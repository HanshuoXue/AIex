import os
import json
import asyncio
from typing import Dict, Any, Optional, List
from promptflow.client import PFClient
from datetime import datetime
import logging
import uuid
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib import colors
from reportlab.lib.units import inch
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from io import BytesIO
import tempfile

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ³¨å†Œä¸­æ–‡å­—ä½“


def register_chinese_fonts():
    """æ³¨å†Œä¸­æ–‡å­—ä½“"""
    try:
        # å°è¯•æ³¨å†Œç³»ç»Ÿä¸­æ–‡å­—ä½“
        import platform
        system = platform.system()

        if system == "Darwin":  # macOS
            font_paths = [
                "/System/Library/Fonts/Supplemental/Arial Unicode.ttf",
                "/System/Library/Fonts/HelveticaNeue.ttc",
                "/System/Library/Fonts/Supplemental/Arial.ttf"
            ]
        elif system == "Windows":
            font_paths = [
                "C:/Windows/Fonts/simsun.ttc",
                "C:/Windows/Fonts/msyh.ttc",
                "C:/Windows/Fonts/simhei.ttf"
            ]
        else:  # Linux
            font_paths = [
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
                "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"
            ]

        # å°è¯•æ³¨å†Œå­—ä½“
        for font_path in font_paths:
            try:
                if os.path.exists(font_path):
                    pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    logger.info(
                        f"Successfully registered Chinese font: {font_path}")
                    return True
            except Exception as e:
                logger.warning(f"Failed to register font {font_path}: {e}")
                continue

        # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
        logger.warning("No Chinese fonts found, using default font")
        return False

    except Exception as e:
        logger.error(f"Error registering Chinese fonts: {e}")
        return False


# åˆå§‹åŒ–æ—¶æ³¨å†Œå­—ä½“
register_chinese_fonts()


class QAAssistant:
    def __init__(self):
        """åˆå§‹åŒ–QAåŠ©æ‰‹"""
        self.pf_client = PFClient()

        # QAåŠ©æ‰‹flowè·¯å¾„ - ä½¿ç”¨æ™ºèƒ½åŒ–Flow
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.flow_path = os.path.join(current_dir, "flows", "qa_assistant")
        self.flow_config = os.path.join(self.flow_path, "flow.dag.yaml")

        # ç¡®ä¿flowè·¯å¾„å­˜åœ¨
        if not os.path.exists(self.flow_path):
            logger.error(f"QA Assistant flow path not found: {self.flow_path}")
        if not os.path.exists(self.flow_config):
            logger.error(
                f"QA Assistant flow config not found: {self.flow_config}")

        # æŠ¥å‘Šå­˜å‚¨ç›®å½•
        self.reports_dir = os.path.join(current_dir, "..", "reports")
        os.makedirs(self.reports_dir, exist_ok=True)

        logger.info(
            f"QA Assistant initialized with flow path: {self.flow_path}")

    async def process_conversation(self, conversation_history: Dict[str, Any], user_message: str, cv_analysis: Dict[str, Any] = None, session_state: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨æ™ºèƒ½Flowå¤„ç†å¯¹è¯
        """
        try:
            logger.info("Processing conversation with intelligent QA flow...")

            # å‡†å¤‡è¾“å…¥æ•°æ®
            flow_inputs = {
                "conversation_history": conversation_history or {"messages": []},
                "user_message": user_message or "",
                "cv_analysis": cv_analysis or {},
                "session_state": session_state or {}
            }

            # è¿è¡Œæ™ºèƒ½QA Flow
            flow_result = self.pf_client.test(
                flow=self.flow_path,  # ä½¿ç”¨flowç›®å½•è€Œä¸æ˜¯specific configæ–‡ä»¶
                inputs=flow_inputs
            )

            logger.info("Intelligent QA flow completed successfully")

            # æå–ç»“æœ
            action = flow_result.get("action", "ask_question")
            next_question = flow_result.get("next_question", "")
            final_report = flow_result.get("final_report", "")
            matched_programs = flow_result.get("matched_programs", [])

            # æ„å»ºå“åº”
            if action == "generate_report" and final_report:
                response = {
                    "response_type": "final_report",
                    "content": final_report,
                    "action": "show_report",
                    "conversation_complete": True,
                    "matched_programs": matched_programs
                }
            elif action == "generate_report":
                response = {
                    "response_type": "generating_report",
                    "content": "å¤ªå¥½äº†ï¼æˆ‘å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯ã€‚ç°åœ¨æ­£åœ¨ä¸ºæ‚¨åŒ¹é…æœ€é€‚åˆçš„é¡¹ç›®å¹¶ç”Ÿæˆä¸ªæ€§åŒ–æŠ¥å‘Š...",
                    "action": "generate_report",
                    "conversation_complete": False
                }
            else:
                response = {
                    "response_type": "question",
                    "content": next_question or "è¯·å‘Šè¯‰æˆ‘æ›´å¤šå…³äºæ‚¨çš„ç•™å­¦éœ€æ±‚ã€‚",
                    "action": "continue_conversation",
                    "conversation_complete": False
                }

            return {
                "success": True,
                "response": response,
                "session_update": {
                    "action": action,
                    "question_count": len([msg for msg in conversation_history.get("messages", []) if msg.get("type") == "user"])
                },
                "flow_result": flow_result
            }

        except Exception as e:
            logger.error(f"Intelligent conversation processing failed: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")

            # è¿”å›fallbackå“åº”
            return {
                "success": False,
                "error": str(e),
                "response": {
                    "response_type": "fallback",
                    "content": "æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨å¯¹æ–°è¥¿å…°ç•™å­¦æœ€å…³å¿ƒçš„æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "action": "continue_conversation",
                    "conversation_complete": False
                },
                "session_update": {
                    "updated_session_state": session_state or {},
                    "updated_conversation_history": conversation_history or {"messages": []}
                }
            }

    async def generate_report(self, cv_analysis: Dict[str, Any], conversation_history: Dict[str, str], user_id: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆä¸ªæ€§åŒ–ç•™å­¦å»ºè®®æŠ¥å‘Š - å®Œæ•´æ¨¡å¼
        ç»“åˆCVåˆ†æã€èŠå¤©å†å²å’Œé¡¹ç›®åŒ¹é…ï¼Œç”Ÿæˆä¸ªæ€§åŒ–æŠ¥å‘Š
        """
        try:
            logger.info(f"Starting report generation for user {user_id}")
            logger.info(
                "ğŸ”„ FULL MODE: Running complete QA Assistant flow for report generation")
            print("ğŸ”„ FULL MODE: Running complete QA Assistant flow for report generation")

            # å‡†å¤‡ç”¨æˆ·ç”»åƒ
            user_profile = {
                "user_id": user_id,
                "analysis_timestamp": datetime.now().isoformat(),
                "basic_info": {
                    "has_cv": bool(cv_analysis),
                    "conversation_completed": len(conversation_history) >= 8
                }
            }

            # è¿è¡ŒQAåŠ©æ‰‹flow
            logger.info("ğŸ”„ å¼€å§‹æ‰§è¡ŒPromptFlow...")
            print("ğŸ”„ å¼€å§‹æ‰§è¡ŒPromptFlow...")

            flow_result = self.pf_client.test(
                flow=self.flow_config,
                inputs={
                    "cv_analysis": cv_analysis or {},
                    "conversation_history": conversation_history,
                    "user_message": "Generate personalized study abroad report",
                    "question_count": 2  # è¡¨ç¤ºå·²ç»é—®å¤Ÿé—®é¢˜ï¼Œå¯ä»¥ç”ŸæˆæŠ¥å‘Š
                }
            )

            logger.info("âœ… Flow execution completed")
            print("âœ… Flow execution completed")
            logger.info(
                f"ğŸ“Š Flow result keys: {list(flow_result.keys()) if flow_result else 'None'}")
            print(
                f"ğŸ“Š Flow result keys: {list(flow_result.keys()) if flow_result else 'None'}")

            # æå–ç»“æœ
            top_programs = flow_result.get("matched_programs", [])
            final_report_content = flow_result.get("final_report", "")

            # è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            debug_info = {
                "flow_result_keys": list(flow_result.keys()) if flow_result else [],
                "matched_programs_count": len(top_programs) if isinstance(top_programs, list) else 0,
                "final_report_length": len(final_report_content) if final_report_content else 0,
                "embedding_status": "unknown",  # å°†åœ¨ä¸‹é¢æ›´æ–°
                "rag_matching_status": "unknown"  # å°†åœ¨ä¸‹é¢æ›´æ–°
            }

            # æ£€æŸ¥embeddingå’ŒRAGçŠ¶æ€
            embedding_result = flow_result.get("embedding_generator", {})
            rag_result = flow_result.get("rag_matcher", {})

            if embedding_result.get("status") == "success":
                debug_info["embedding_status"] = "success"
                debug_info["embedding_dimension"] = embedding_result.get(
                    "dimension", 0)
            else:
                debug_info["embedding_status"] = "fallback_used"
                debug_info["embedding_error"] = embedding_result.get(
                    "error", "unknown")

            if rag_result.get("status") == "success":
                debug_info["rag_matching_status"] = "success"
                debug_info["rag_programs_count"] = rag_result.get(
                    "programs_count", 0)
            else:
                debug_info["rag_matching_status"] = "fallback_used"
                debug_info["rag_reason"] = rag_result.get("reason", "unknown")

            logger.info(f"ğŸ” Debug info: {debug_info}")
            print(f"ğŸ” Debug info: {debug_info}")

            # ç”ŸæˆPDFæŠ¥å‘Š
            report_filename = f"study_report_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            report_path = os.path.join(self.reports_dir, report_filename)

            pdf_success = await self.generate_pdf_report(
                cv_analysis=cv_analysis,
                matched_programs=top_programs,
                conversation_history=conversation_history,
                user_profile=user_profile,
                final_report_content=final_report_content,
                output_path=report_path
            )

            if pdf_success:
                # è¿”å›æˆåŠŸç»“æœ
                return {
                    "success": True,
                    "report_url": f"/api/reports/{report_filename}",
                    "report_path": report_path,
                    "programs_matched": len(top_programs) if isinstance(top_programs, list) else 0,
                    "generation_time": datetime.now().isoformat(),
                    "generation_mode": "FULL_MODE",
                    "flow_details": {
                        "matching_status": "completed",
                        "matching_strategy": "full_llm_analysis"
                    },
                    "debug_info": debug_info,
                    "flow_result": flow_result  # åŒ…å«å®Œæ•´çš„flowç»“æœ
                }
            else:
                return {
                    "success": False,
                    "error": "PDF report generation failed",
                    "flow_result": flow_result
                }

        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")

            return {
                "success": False,
                "error": f"Report generation failed: {str(e)}",
                "details": str(e)
            }

    async def generate_pdf_report(self, cv_analysis: Dict[str, Any], matched_programs: list, conversation_history: Dict[str, str], user_profile: Dict[str, Any], final_report_content: str, output_path: str) -> bool:
        """
        ç”ŸæˆPDFæŠ¥å‘Š - ä½¿ç”¨LLMæ¨¡æ¿ç”Ÿæˆè‹±æ–‡å†…å®¹
        """
        try:
            logger.info(f"Generating PDF report: {output_path}")

            # ä½¿ç”¨å·²ç»ç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹
            report_content = final_report_content

            # åˆ›å»ºPDFæ–‡æ¡£
            doc = SimpleDocTemplate(output_path, pagesize=A4)
            styles = getSampleStyleSheet()
            story = []

            # å¼ºåˆ¶ä½¿ç”¨Helveticaå­—ä½“ï¼Œé¿å…ç¼–ç é—®é¢˜
            base_font = 'Helvetica'
            logger.info(
                f"Using font: {base_font} (forced to avoid encoding issues)")
            print(
                f"PDF Generation - Using font: {base_font} (forced to avoid encoding issues)")

            # æ›´æ–°é»˜è®¤æ ·å¼ä»¥ä½¿ç”¨Helvetica
            for style_name in ['Normal', 'Heading1', 'Heading2', 'Heading3', 'Heading4']:
                if style_name in styles:
                    styles[style_name].fontName = base_font

            # æ ‡é¢˜
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontName=base_font,
                fontSize=20,
                spaceAfter=20,
                textColor=colors.darkblue,
                alignment=1
            )

            story.append(Paragraph(
                "New Zealand Study Abroad Personalized Recommendation Report", title_style))
            story.append(Spacer(1, 20))
            story.append(
                Paragraph(f"Generated on: {datetime.now().strftime('%B %d, %Y')}", styles['Normal']))
            story.append(Spacer(1, 20))

            # ä½¿ç”¨LLMç”Ÿæˆçš„å†…å®¹
            content_lines = report_content.split('\n')
            for line in content_lines:
                line = line.strip()
                if not line:
                    story.append(Spacer(1, 6))
                else:
                    # è¿‡æ»¤éASCIIå­—ç¬¦ï¼Œç¡®ä¿åªæœ‰è‹±æ–‡
                    filtered_line = ''.join(
                        char for char in line if ord(char) < 128)

                    if filtered_line.startswith('# '):
                        story.append(
                            Paragraph(filtered_line[2:], styles['Heading1']))
                    elif filtered_line.startswith('## '):
                        story.append(
                            Paragraph(filtered_line[3:], styles['Heading2']))
                    elif filtered_line.startswith('### '):
                        story.append(
                            Paragraph(filtered_line[4:], styles['Heading3']))
                    elif filtered_line.startswith('- '):
                        story.append(
                            Paragraph(f"â€¢ {filtered_line[2:]}", styles['Normal']))
                    else:
                        story.append(
                            Paragraph(filtered_line, styles['Normal']))
                    story.append(Spacer(1, 3))

            # æ„å»ºPDF
            doc.build(story)

            # éªŒè¯PDFæ–‡ä»¶
            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                logger.info(
                    f"PDF report generated successfully: {output_path} (size: {os.path.getsize(output_path)} bytes)")
                return True
            else:
                logger.error(f"PDF file not created or empty: {output_path}")
                return False

        except Exception as e:
            logger.error(f"PDF generation failed: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            return False

    async def generate_llm_report_content(self, cv_analysis: Dict[str, Any], matched_programs: list, conversation_history: Dict[str, str], user_profile: Dict[str, Any]) -> str:
        """
        ä½¿ç”¨LLMç”Ÿæˆè‹±æ–‡æŠ¥å‘Šå†…å®¹ - å®Œå…¨ä¸ªæ€§åŒ–ï¼Œæ— é¢„å¡«å†™æ¨¡æ¿
        """
        try:
            logger.info(
                "Generating personalized report content using PromptFlow LLM")

            # è°ƒç”¨PromptFlowç”Ÿæˆå®Œå…¨ä¸ªæ€§åŒ–çš„æŠ¥å‘Šå†…å®¹
            logger.info(
                f"Calling PromptFlow with inputs: cv_analysis={bool(cv_analysis)}, conversation_history={len(conversation_history)}")

            response = self.pf_client.test(
                flow=self.flow_config,
                inputs={
                    "cv_analysis": cv_analysis,
                    "conversation_history": conversation_history,
                    "user_message": "Generate personalized study abroad report",
                    "question_count": 2  # è¡¨ç¤ºå·²ç»é—®å¤Ÿé—®é¢˜ï¼Œå¯ä»¥ç”ŸæˆæŠ¥å‘Š
                }
            )

            logger.info(
                f"PromptFlow response keys: {list(response.keys()) if response else 'None'}")
            logger.info(f"PromptFlow response: {response}")

            # æå–ç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹
            report_content = response.get("final_report", "")

            if not report_content:
                logger.warning(
                    "LLM did not return report content, using fallback")
                logger.warning(f"Response was: {response}")
                report_content = self.generate_fallback_report(
                    cv_analysis, matched_programs, conversation_history)
            else:
                logger.info(
                    "Successfully generated personalized report content from LLM")
                logger.info(f"Report content length: {len(report_content)}")

            return report_content

        except Exception as e:
            logger.error(f"LLM report generation failed: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            # ä½¿ç”¨å¤‡ç”¨æ¨¡æ¿
            return self.generate_fallback_report(cv_analysis, matched_programs, conversation_history)

    def generate_fallback_report(self, cv_analysis: Dict[str, Any], matched_programs: list, conversation_history: Dict[str, str]) -> str:
        """
        å¤‡ç”¨æŠ¥å‘Šæ¨¡æ¿ï¼ˆå½“LLMå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        """
        return """# Study Abroad Report Generation Failed

We apologize, but we were unable to generate your personalized study abroad report at this time. 

Please try again or contact support if the issue persists.

## Error Information
- CV Analysis: Available
- Conversation History: Available  
- Matched Programs: Available
- Report Generation: Failed

Please retry the report generation process.
"""


# å…¨å±€å®ä¾‹
qa_assistant = QAAssistant()

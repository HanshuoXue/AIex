$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
inputs:
  candidate_profile:
    type: string
    description: Candidate information in JSON format
  qa_answers:
    type: object
    description: Q&A answers from CV analysis
    default: {}
  cv_analysis:
    type: object
    description: AI analysis results from CV
    default: {}
  program_details:
    type: string
    description: Program information in JSON format (single program)
    default: ""
  programs_batch:
    type: string
    description: Multiple programs information in JSON format (batch processing)
    default: ""
  use_batch:
    type: string
    description: Flag to enable batch processing
    default: "false"
outputs:
  match_result:
    type: object
    reference: ${match_evaluator.output}
  batch_evaluations:
    type: object
    reference: ${batch_evaluator.output}
nodes:
  - name: match_prompt
    type: llm
    source:
      type: code
      path: match_prompt.jinja2
    inputs:
      candidate: ${inputs.candidate_profile}
      qa_answers: ${inputs.qa_answers}
      cv_analysis: ${inputs.cv_analysis}
      program: ${inputs.program_details}
      deployment_name: gpt-4
      max_tokens: 800
      temperature: 0.1
    connection: azure_openai_connection
    api: chat
    activate:
      when: ${inputs.use_batch}
      is: "false"
  - name: match_evaluator
    type: python
    source:
      type: code
      path: match_evaluator.py
    inputs:
      llm_response: ${match_prompt.output}
      candidate_data: ${inputs.candidate_profile}
      program_data: ${inputs.program_details}
    activate:
      when: ${inputs.use_batch}
      is: "false"
  - name: batch_match_prompt
    type: llm
    source:
      type: code
      path: batch_match_prompt.jinja2
    inputs:
      candidate: ${inputs.candidate_profile}
      qa_answers: ${inputs.qa_answers}
      cv_analysis: ${inputs.cv_analysis}
      programs: ${inputs.programs_batch}
      deployment_name: gpt-4
      max_tokens: 4000
      temperature: 0.1
    connection: azure_openai_connection
    api: chat
    activate:
      when: ${inputs.use_batch}
      is: "true"
  - name: batch_evaluator
    type: python
    source:
      type: code
      path: batch_evaluator.py
    inputs:
      llm_response: ${batch_match_prompt.output}
      candidate_data: ${inputs.candidate_profile}
      programs_data: ${inputs.programs_batch}
    activate:
      when: ${inputs.use_batch}
      is: "true"

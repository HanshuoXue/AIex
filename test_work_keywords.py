#!/usr/bin/env python3
"""
Test work experience keyword extraction functionality
"""

import sys
import os

# æ·»åŠ apiç›®å½•åˆ°è·¯å¾„
api_path = os.path.join(os.path.dirname(__file__), 'api')
sys.path.insert(0, api_path)

# ç›´æ¥å¤åˆ¶å‡½æ•°ï¼Œé¿å…å¯¼å…¥é—®é¢˜


def extract_work_experience_keywords(cv_text: str) -> str:
    """
    ä»CVæ–‡æœ¬ä¸­æå–å·¥ä½œç»å†ç›¸å…³çš„å…³é”®è¯
    """
    import re

    # å·¥ä½œç»å†ç›¸å…³çš„å…³é”®è¯æ¨¡å¼
    work_patterns = [
        # è‹±æ–‡å…³é”®è¯
        r'\b(?:work|working|worked|employment|employed|job|position|role|career)\b',
        r'\b(?:experience|experiences|professional|occupation|industry)\b',
        r'\b(?:company|corporation|firm|organization|startup|enterprise)\b',
        r'\b(?:manager|developer|engineer|analyst|consultant|specialist|director)\b',
        r'\b(?:intern|internship|volunteer|project|team|lead|senior|junior)\b',

        # ä¸­æ–‡å…³é”®è¯
        r'(?:å·¥ä½œ|å°±ä¸š|èŒä¸š|å²—ä½|èŒä½|è§’è‰²|ç»å†)',
        r'(?:å…¬å¸|ä¼ä¸š|æœºæ„|ç»„ç»‡|å›¢é˜Ÿ|éƒ¨é—¨)',
        r'(?:ç»ç†|å¼€å‘|å·¥ç¨‹å¸ˆ|åˆ†æå¸ˆ|é¡¾é—®|ä¸“å®¶|ä¸»ç®¡)',
        r'(?:å®ä¹ |é¡¹ç›®|è´Ÿè´£|å‚ä¸|ç®¡ç†|é¢†å¯¼)',
    ]

    extracted_keywords = set()
    cv_text_lower = cv_text.lower()

    # æå–åŒ¹é…çš„å…³é”®è¯
    for pattern in work_patterns:
        matches = re.findall(pattern, cv_text_lower, re.IGNORECASE)
        extracted_keywords.update(matches)

    # é¢å¤–æå–å·¥ä½œç›¸å…³çš„ä¸“æœ‰åè¯ (å…¬å¸åã€æŠ€æœ¯æ ˆç­‰)
    # å¯»æ‰¾å¯èƒ½çš„å…¬å¸å (å¤§å†™å­—æ¯å¼€å¤´çš„è¯)
    company_pattern = r'\b[A-Z][a-zA-Z]{2,}\s*(?:Inc|Corp|Ltd|LLC|Technology|Tech|Software|Systems|Solutions|Group|Company)?\b'
    company_matches = re.findall(company_pattern, cv_text)

    # æŠ€æœ¯ç›¸å…³å…³é”®è¯
    tech_patterns = [
        r'\b(?:Python|Java|JavaScript|C\+\+|React|Node\.js|SQL|AWS|Azure|Docker)\b',
        r'\b(?:machine learning|artificial intelligence|data science|backend|frontend)\b',
        r'\b(?:agile|scrum|git|github|database|API|microservices|cloud)\b'
    ]

    for pattern in tech_patterns:
        tech_matches = re.findall(pattern, cv_text, re.IGNORECASE)
        extracted_keywords.update([match.lower() for match in tech_matches])

    # é™åˆ¶å…³é”®è¯æ•°é‡ï¼Œé¿å…queryè¿‡é•¿
    keywords_list = list(extracted_keywords)[:10]  # æœ€å¤š10ä¸ªå…³é”®è¯

    return ' '.join(keywords_list)


def test_work_keywords_extraction():
    """Test work experience keyword extraction"""

    # Testæ ·æœ¬CVæ–‡æœ¬
    sample_cv = """
    PROFESSIONAL SUMMARY
    AI & Software Development | Master of IT (Mar 2026) | Bridging business and technology
    
    WORK EXPERIENCE
    Intelligence Engineer Intern                     Jun. 2022 - Aug. 2022
    Technology Company, Beijing
    â€¢ Executed 4+ ML projects spanning bioinformatics
    â€¢ Worked with Python, JavaScript, and machine learning
    â€¢ Developed backend APIs using Node.js
    â€¢ Collaborated with team of 5 engineers
    
    Software Developer                              Jan. 2021 - May 2022  
    Startup Inc, Shanghai
    â€¢ Built web applications using React and SQL
    â€¢ Managed database systems and cloud infrastructure
    â€¢ Led agile development process
    
    é¡¹ç›®ç»å†ï¼š
    äººå·¥æ™ºèƒ½é¡¹ç›®è´Ÿè´£äºº                              2020years9æœˆ - 2021years12æœˆ
    â€¢ è´Ÿè´£æœºå™¨å­¦ä¹ æ¨¡å‹å¼€å‘
    â€¢ å‚ä¸å›¢é˜Ÿç®¡ç†å’ŒæŠ€æœ¯å†³ç­–
    â€¢ ä½¿ç”¨AWSäº‘æœåŠ¡éƒ¨ç½²ç³»ç»Ÿ
    """

    print("ğŸ” Test work experience keyword extraction...")
    print("=" * 50)

    keywords = extract_work_experience_keywords(sample_cv)

    print(f"ğŸ“ Original CV snippet:")
    print(sample_cv[:200] + "...")
    print()

    print(f"ğŸ¯ Extracted work keywords:")
    print(f"'{keywords}'")
    print()

    # åˆ†æå…³é”®è¯
    keyword_list = keywords.split() if keywords else []
    print(f"ğŸ“Š Keyword analysis:")
    print(f"- æ€»æ•°: {len(keyword_list)}")
    print(f"- è¯¦ç»†åˆ—è¡¨: {keyword_list}")
    print()

    # éªŒè¯é¢„æœŸå…³é”®è¯æ˜¯å¦è¢«æå–
    expected_keywords = [
        'professional', 'work', 'experience', 'engineer', 'intern',
        'developer', 'company', 'team', 'project', 'python',
        'javascript', 'machine', 'learning', 'backend', 'react'
    ]

    found_keywords = []
    for expected in expected_keywords:
        if expected in keyword_list:
            found_keywords.append(expected)

    print(f"âœ… Successfully extracted expected keywords: {found_keywords}")
    print(f"ğŸ“ˆ Extraction success rate: {len(found_keywords)}/{len(expected_keywords)} ({len(found_keywords)/len(expected_keywords)*100:.1f}%)")

    return keywords


def test_query_enhancement():
    """Test query enhancement effect"""

    print("\n" + "=" * 50)
    print("ğŸš€ Test query enhancement effect...")

    # æ¨¡æ‹Ÿå€™é€‰äººæ•°æ®
    candidate_data = {
        'bachelor_major': 'computer science',
        'interests': ['machine learning', 'artificial intelligence']
    }

    # Original query
    base_query = f"{candidate_data['bachelor_major']} {' '.join(candidate_data['interests'])}"
    print(f"ğŸ“ Original query: '{base_query}'")

    # æå–å·¥ä½œå…³é”®è¯
    sample_cv = """
    Software Engineer at Google Inc
    Worked on machine learning projects using Python and TensorFlow
    Professional experience in cloud computing and database management
    """

    work_keywords = extract_work_experience_keywords(sample_cv)
    enhanced_query = f"{base_query} {work_keywords}".strip()

    print(f"ğŸ” å·¥ä½œå…³é”®è¯: '{work_keywords}'")
    print(f"ğŸ¯ Enhanced query: '{enhanced_query}'")

    print(f"\nğŸ“Š Query comparison:")
    print(f"- Original length: {len(base_query.split())} è¯")
    print(f"- Enhanced length: {len(enhanced_query.split())} è¯")
    print(
        f"- Enhancement ratio: {len(enhanced_query.split())/len(base_query.split()):.1f}x")


if __name__ == "__main__":
    print("ğŸ§ª å·¥ä½œç»å†å…³é”®è¯æå–Test")
    print("=" * 50)

    # Test1: å…³é”®è¯æå–
    keywords = test_work_keywords_extraction()

    # Test2: æŸ¥è¯¢å¢å¼º
    test_query_enhancement()

    print("\nâœ… Test completedï¼")

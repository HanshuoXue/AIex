#!/usr/bin/env python3
"""
Testç®€åŒ–çš„RAG CVåˆ†æåŠŸèƒ½
"""
import os
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
api_path = project_root / "api"
sys.path.insert(0, str(api_path))
sys.path.insert(0, str(api_path / "flows" / "chat_rag"))


def test_simple_chunking():
    """Testç®€å•Tokenåˆ‡å—"""
    print("ğŸ” Testç®€å•Tokenåˆ‡å—...")

    try:
        from api.flows.chat_rag.simple_chunker import simple_chunk_by_tokens, get_relevant_chunks_simple, format_chunks_for_llm

        test_cv = """
        John Doe
        Senior Software Engineer
        Email: john.doe@email.com
        Phone: +1234567890
        
        EDUCATION
        Bachelor of Computer Science
        Stanford University
        2018-2022
        GPA: 3.8/4.0
        
        WORK EXPERIENCE
        Senior Software Engineer
        Tech Innovations Inc.
        June 2022 - Present
        â€¢ Developed scalable web applications serving 100K+ users
        â€¢ Led a team of 5 developers in agile environment
        â€¢ Implemented microservices architecture reducing latency by 40%
        
        Software Developer
        StartUp Solutions
        January 2020 - May 2022
        â€¢ Built responsive web applications using React and Redux
        â€¢ Developed RESTful APIs with Node.js and Express
        
        TECHNICAL SKILLS
        Programming Languages: JavaScript, TypeScript, Python, Java
        Frontend: React, Redux, HTML5, CSS3
        Backend: Node.js, Express, Django
        Databases: PostgreSQL, MongoDB
        """

        # 1. TestChunk
        chunks = simple_chunk_by_tokens(
            test_cv, max_tokens=400, overlap_tokens=50)
        print(f"âœ… Generated {len(chunks)} chunks")

        for i, chunk in enumerate(chunks[:3]):
            print(
                f"  Chunk {i+1}: {chunk['estimated_tokens']} tokens, {chunk['length']} characters")
            print(f"  Content: {chunk['text'][:80]}...")

        # 2. Testæ£€ç´¢
        relevant = get_relevant_chunks_simple(
            chunks, "software engineering experience", top_k=3)
        print(f"âœ… æ£€ç´¢åˆ° {len(relevant)} relevant chunks")

        for chunk in relevant:
            print(f"  - Chunk {chunk['id']}: RelevanceScore {chunk['relevance_score']}")

        # 3. Testæ ¼å¼åŒ–
        formatted = format_chunks_for_llm(relevant)
        print(f"âœ… æ ¼å¼åŒ–åLength: {len(formatted)} characters")
        print(f"æ ¼å¼åŒ–é¢„è§ˆ:\n{formatted[:200]}...")

        return True

    except Exception as e:
        print(f"âŒ ç®€å•ChunkTestå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_question_generation():
    """Testé—®é¢˜ç”Ÿæˆ"""
    print("\nğŸ” Testé—®é¢˜ç”Ÿæˆ...")

    try:
        from api.flows.chat_rag.simple_question_generator import generate_questions_from_chunks

        test_chunks = """
--- CV segment 1 ---
Length: 300 characters
Estimated tokens: 75
Relevance: 3
Content:
WORK EXPERIENCE
Senior Software Engineer
Tech Innovations Inc.
June 2022 - Present
â€¢ Developed scalable web applications serving 100K+ users
â€¢ Led a team of 5 developers in agile environment

--- CV segment 2 ---
Length: 200 characters  
Estimated tokens: 50
Relevance: 2
Content:
EDUCATION
Bachelor of Computer Science
Stanford University
2018-2022
GPA: 3.8/4.0
"""

        test_candidate = {
            "bachelor_major": "computer science",
            "gpa_value": 3.5,
            "gpa_scale": "4.0",
            "ielts_overall": 7.0,
            "work_years": 2,
            "interests": ["machine learning", "web development"],
            "city_pref": ["Auckland"],
            "budget_nzd_per_year": 50000
        }

        result = generate_questions_from_chunks(test_chunks, test_candidate)

        if result.get("status") == "success":
            questions = result["data"]["questions"]
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(questions)} ä¸ªé—®é¢˜")

            for i, q in enumerate(questions, 1):
                print(f"\né—®é¢˜ {i}:")
                print(f"  Content: {q['question']}")
                print(f"  åŸå› : {q['reason']}")
                print(f"  å¿…å¡«: {q['required']}")
        else:
            print("âš ï¸ ä½¿ç”¨å¤‡ç”¨é—®é¢˜")
            fallback = result.get("fallback_questions", {})
            questions = fallback.get("questions", [])
            print(f"âœ… å¤‡ç”¨é—®é¢˜æ•°é‡: {len(questions)}")

        return True

    except Exception as e:
        print(f"âŒ é—®é¢˜ç”ŸæˆTestå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_integrated_flow():
    """Testå®Œæ•´æµç¨‹"""
    print("\nğŸ” Testå®Œæ•´RAGæµç¨‹...")

    try:
        from api.flows.chat_rag.simple_chunker import simple_chunk_by_tokens, get_relevant_chunks_simple, format_chunks_for_llm
        from api.flows.chat_rag.simple_question_generator import generate_questions_from_chunks

        # æ¨¡æ‹Ÿå®Œæ•´CVæ–‡æœ¬
        cv_text = """
        å¼ ä¸‰
        é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆ
        ç”µè¯: 138xxxx8888
        é‚®ç®±: zhangsan@email.com
        
        æ•™è‚²èƒŒæ™¯
        è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦å£«
        åŒ—äº¬å¤§å­¦
        2016-2020
        GPA: 3.6/4.0
        
        å·¥ä½œç»å†
        é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆ
        å­—èŠ‚è·³åŠ¨
        2021years3æœˆ - è‡³ä»Š
        â€¢ è´Ÿè´£æ¨èç³»ç»Ÿç®—æ³•ä¼˜åŒ–ï¼Œæå‡CTR 15%
        â€¢ å¸¦é¢†6äººå›¢é˜Ÿå¼€å‘å¾®æœåŠ¡æ¶æ„
        â€¢ ä½¿ç”¨Pythonã€Goã€ReactæŠ€æœ¯æ ˆ
        
        è½¯ä»¶å·¥ç¨‹å¸ˆ
        ç¾å›¢
        2020years7æœˆ - 2021years3æœˆ
        â€¢ å¼€å‘å¤–å–é…é€ç®—æ³•
        â€¢ ç»´æŠ¤é«˜å¹¶å‘ç³»ç»Ÿï¼Œæ—¥æ´»1000ä¸‡+
        
        æŠ€èƒ½
        ç¼–ç¨‹è¯­è¨€: Python, Java, Go, JavaScript
        æ¡†æ¶: Django, Spring Boot, React, Vue
        æ•°æ®åº“: MySQL, Redis, MongoDB
        äº‘æœåŠ¡: AWS, é˜¿é‡Œäº‘
        
        é¡¹ç›®ç»å†
        æ™ºèƒ½æ¨èç³»ç»Ÿ
        2022years
        â€¢ è®¾è®¡å¹¶å®ç°åŸºäºæ·±åº¦å­¦ä¹ çš„æ¨èç®—æ³•
        â€¢ ä½¿ç”¨TensorFlowå’ŒPyTorch
        â€¢ ç³»ç»Ÿæ—¥å¤„ç†è¯·æ±‚é‡è¾¾1äº¿æ¬¡
        """

        candidate_info = {
            "bachelor_major": "computer science",
            "gpa_value": 3.6,
            "gpa_scale": "4.0",
            "ielts_overall": 7.5,
            "work_years": 3,
            "interests": ["machine learning", "artificial intelligence"],
            "city_pref": ["Wellington", "Auckland"],
            "budget_nzd_per_year": 60000
        }

        # å®Œæ•´æµç¨‹
        print("Step 1: Text chunking...")
        chunks = simple_chunk_by_tokens(
            cv_text, max_tokens=400, overlap_tokens=50)
        print(f"  ç”Ÿæˆ {len(chunks)} chunks")

        print("æ­¥éª¤2: Relevanceæ£€ç´¢...")
        query = f"{candidate_info.get('bachelor_major', '')} {' '.join(candidate_info.get('interests', []))}"
        relevant_chunks = get_relevant_chunks_simple(chunks, query, top_k=5)
        print(f"  é€‰æ‹© {len(relevant_chunks)} relevant chunks")

        print("æ­¥éª¤3: æ ¼å¼åŒ–Chunk...")
        formatted_chunks = format_chunks_for_llm(relevant_chunks)
        print(f"  æ ¼å¼åŒ–Length: {len(formatted_chunks)} characters")

        print("æ­¥éª¤4: ç”Ÿæˆé—®é¢˜...")
        question_result = generate_questions_from_chunks(
            formatted_chunks, candidate_info)

        if question_result.get("status") == "success":
            questions = question_result["data"]["questions"]
            summary = question_result["data"].get("analysis_summary", "")
            print(f"âœ… å®Œæ•´æµç¨‹æˆåŠŸ!")
            print(f"  ç”Ÿæˆé—®é¢˜æ•°: {len(questions)}")
            print(f"  åˆ†ææ‘˜è¦: {summary}")
        else:
            print("âš ï¸ Question generation failedï¼Œä½¿ç”¨å¤‡ç”¨é—®é¢˜")

        return True

    except Exception as e:
        print(f"âŒ å®Œæ•´æµç¨‹Testå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰Test"""
    print("ğŸš€ ç®€åŒ–RAG CVåˆ†æTest\n")

    results = []

    # è¿è¡ŒTest
    results.append(test_simple_chunking())
    results.append(test_question_generation())
    results.append(test_integrated_flow())

    # æ±‡æ€»ç»“æœ
    print(f"\n{'='*50}")
    print("ğŸ“Š Testç»“æœæ±‡æ€»:")
    print(f"{'='*50}")

    test_names = ["ç®€å•Chunk", "é—®é¢˜ç”Ÿæˆ", "å®Œæ•´æµç¨‹"]
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{i+1}. {name}: {status}")

    total_passed = sum(results)
    total_tests = len(results)

    print(f"\næ€»è®¡: {total_passed}/{total_tests} Testé€šè¿‡")

    if total_passed == total_tests:
        print("ğŸ‰ æ‰€æœ‰Testé€šè¿‡ï¼ç®€åŒ–RAGç³»ç»Ÿå·²å°±ç»ªã€‚")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†Testå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
